import argparse
import os
import random
import time
import requests
import subprocess
from pathlib import Path

from env_utils import load_dotenv

def _default_data_dir(rel: str, fallback: str) -> str:
    """
    Prefer Docker volume (/data) when present, because /work is mounted read-only.
    """
    if os.path.isdir("/data"):
        return os.path.join("/data", rel)
    return fallback


# Directories for downloaded files and extracted files
DOWNLOAD_DIR = os.getenv("MB_DOWNLOAD_DIR") or _default_data_dir("download", "download")
UNZIP_DIR = os.getenv("MB_UNZIP_DIR") or _default_data_dir("unzip", "unzip")

MB_API_URL = "https://mb-api.abuse.ch/api/v1/"


def _env_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, str(default)).strip() or default)
    except ValueError:
        return default


def _sleep_jitter(kind: str, verbose: bool) -> None:
    mn = _env_int("MB_SLEEP_MIN", 1)
    mx = _env_int("MB_SLEEP_MAX", 4)
    if mn < 0:
        mn = 0
    if mx < mn:
        mx = mn
    if mx == 0:
        return
    s = random.uniform(float(mn), float(mx))
    if verbose:
        print(f"[INFO] {kind} sleep {s:.2f}s (MB_SLEEP_MIN={mn}, MB_SLEEP_MAX={mx})")
    time.sleep(s)


def _backoff_sleep(attempt: int, verbose: bool) -> None:
    base = _env_int("MB_RETRY_BASE_SLEEP", 2)
    cap = _env_int("MB_RETRY_MAX_SLEEP", 60)
    s = min(cap, base * (2 ** max(0, attempt - 1)))
    s = random.uniform(0.8 * s, 1.2 * s)
    if verbose:
        print(f"[INFO] retry backoff sleep {s:.2f}s (attempt {attempt})")
    time.sleep(max(0.0, s))


def _looks_like_zip(path: str) -> bool:
    try:
        with open(path, "rb") as f:
            return f.read(4) == b"PK\x03\x04"
    except OSError:
        return False


def download_sample(sess: requests.Session, api_key: str, sha256_hash: str, verbose: bool = False) -> str | None:
    headers = {"Auth-Key": api_key}
    data = {"query": "get_file", "sha256_hash": sha256_hash}

    if verbose:
        print(f"[INFO] Downloading sample for hash: {sha256_hash}")

    retry_max = _env_int("MB_RETRY_MAX", 5)
    timeout_s = _env_int("MB_TIMEOUT", 180)
    zip_path = os.path.join(DOWNLOAD_DIR, f"{sha256_hash}.zip")
    tmp_path = zip_path + ".part"

    for attempt in range(1, max(1, retry_max) + 1):
        _sleep_jitter("pre-download", verbose)
        try:
            with sess.post(MB_API_URL, headers=headers, data=data, stream=True, timeout=timeout_s) as r:
                status = r.status_code
                if status == 429 or status >= 500:
                    if verbose:
                        print(f"[WARN] HTTP {status} for {sha256_hash} (attempt {attempt}/{retry_max})")
                    _backoff_sleep(attempt, verbose)
                    continue
                if status != 200:
                    if verbose:
                        print(f"[ERROR] Failed to download {sha256_hash}, status code: {status}")
                    return None

                os.makedirs(DOWNLOAD_DIR, exist_ok=True)
                bytes_written = 0
                with open(tmp_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=1024 * 128):
                        if not chunk:
                            continue
                        f.write(chunk)
                        bytes_written += len(chunk)

                if bytes_written == 0:
                    if verbose:
                        print(f"[WARN] Empty body for {sha256_hash} (attempt {attempt}/{retry_max})")
                    try:
                        os.remove(tmp_path)
                    except OSError:
                        pass
                    _backoff_sleep(attempt, verbose)
                    continue

                os.replace(tmp_path, zip_path)
                if not _looks_like_zip(zip_path):
                    if verbose:
                        print(f"[WARN] Downloaded file is not ZIP for {sha256_hash}: {zip_path}")
                    return None

                if verbose:
                    print(f"[INFO] Sample saved to: {zip_path} ({bytes_written} bytes)")
                return zip_path
        except requests.exceptions.RequestException as e:
            if verbose:
                print(f"[WARN] Download error for {sha256_hash} (attempt {attempt}/{retry_max}): {e}")
            try:
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)
            except OSError:
                pass
            if attempt < retry_max:
                _backoff_sleep(attempt, verbose)
                continue
            return None

def extract_with_7z(zip_path, verbose=False):
    if not os.path.exists(UNZIP_DIR):
        os.makedirs(UNZIP_DIR)

    command = [
        "7z", "x",
        "-y",
        "-aoa",
        zip_path,
        f"-o{UNZIP_DIR}",  # Output directory
        "-p" + os.getenv("MB_ZIP_PASSWORD", "infected"),
    ]

    try:
        if verbose:
            print(f"[INFO] Extracting {zip_path} using 7z...")
        result = subprocess.run(command, capture_output=True, text=True)

        if result.returncode == 0:
            if verbose:
                print(f"[INFO] Extracted contents to: {UNZIP_DIR}")
        else:
            if verbose:
                print(f"[ERROR] Failed to extract {zip_path}. Error: {result.stderr}")
    except FileNotFoundError:
        if verbose:
            print("[ERROR] 7z is not installed or not found in PATH. Please install 7z to use this script.")


def _is_nested_archive(p: Path) -> bool:
    return p.is_file() and p.suffix.lower() in {".zip", ".7z", ".rar"}


def _run_7z_extract(cmd: list[str], verbose: bool) -> int:
    if verbose:
        print(f"[INFO] Nested extract cmd: {' '.join(cmd)}")
    r = subprocess.run(cmd, capture_output=True, text=True)
    if r.returncode != 0 and verbose:
        msg = (r.stderr or r.stdout or "").strip()
        if msg:
            tail = msg.splitlines()[-3:]
            print("[WARN] 7z error:", " | ".join(tail))
    return r.returncode


def _try_extract_archive(archive_path: Path, out_dir: Path, passwords: list[str], verbose: bool) -> bool:
    """
    For nested archives we don't know whether it's encrypted; try no password first,
    then try provided passwords.
    """
    out_dir.mkdir(parents=True, exist_ok=True)
    base = ["7z", "x", "-y", "-aoa", str(archive_path), f"-o{out_dir}"]
    if _run_7z_extract(base, verbose) == 0:
        return True
    for pw in passwords:
        pw = (pw or "").strip()
        if not pw:
            continue
        if _run_7z_extract(base + [f"-p{pw}"], verbose) == 0:
            return True
    return False


def recursive_extract_nested(unzip_dir: str, depth: int, move_archives: bool, verbose: bool) -> None:
    """
    Extract nested archives (zip/7z/rar) under unzip_dir into unzip_dir/_nested/...
    This keeps outputs inside the same tree so YARA can scan recursively.
    """
    if depth <= 0:
        return

    root = Path(unzip_dir)
    nested_root = root / "_nested"
    archives_root = root / "_archives"

    # Priority: explicit nested password > MB_ZIP_PASSWORD > "infected"
    passwords: list[str] = []
    for key in ("MB_NESTED_PASSWORD", "MB_ZIP_PASSWORD"):
        v = (os.getenv(key) or "").strip()
        if v and v not in passwords:
            passwords.append(v)
    if "infected" not in passwords:
        passwords.append("infected")

    # start from top-level files to avoid infinite loops
    current = [p for p in root.iterdir() if _is_nested_archive(p)]
    if verbose:
        print(f"[INFO] Nested archives found at top-level: {len(current)}")

    for p in current:
        out_dir = nested_root / p.stem
        ok = _try_extract_archive(p, out_dir, passwords=passwords, verbose=verbose)
        if not ok:
            if verbose:
                print(f"[WARN] Failed to extract nested archive: {p}")
            continue
        if move_archives:
            archives_root.mkdir(parents=True, exist_ok=True)
            try:
                p.replace(archives_root / p.name)
            except OSError:
                pass

    # optional additional depth: extract archives found inside _nested
    for _ in range(1, depth):
        more = [p for p in nested_root.rglob("*") if _is_nested_archive(p)]
        if not more:
            break
        if verbose:
            print(f"[INFO] Nested archives found inside _nested: {len(more)}")
        for p in more:
            out_dir = p.parent / (p.stem + "_x")
            ok = _try_extract_archive(p, out_dir, passwords=passwords, verbose=verbose)
            if (not ok) and verbose:
                print(f"[WARN] Failed to extract nested archive: {p}")

def main():
    load_dotenv()
    global DOWNLOAD_DIR, UNZIP_DIR
    DOWNLOAD_DIR = os.getenv("MB_DOWNLOAD_DIR") or DOWNLOAD_DIR
    UNZIP_DIR = os.getenv("MB_UNZIP_DIR") or UNZIP_DIR
    # Argument parser
    parser = argparse.ArgumentParser(description="Download and extract malware samples from MalwareBazaar.")
    parser.add_argument(
        "-k",
        "--api_key",
        help="MalwareBazaar API key. If not provided, MB_API_KEY env var (and .env) will be used.",
    )
    parser.add_argument("-H", "--hash", help="Single file hash to download and extract.")
    parser.add_argument("-f", "--file", help="File containing a list of hashes (one per line).")
    parser.add_argument(
        "--limit",
        type=int,
        default=0,
        help="When using --file, process at most N hashes (0 = no limit).",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Do not download/extract. Only print which hashes would be processed.",
    )
    parser.add_argument(
        "--recursive-extract",
        action="store_true",
        help="Also extract nested archives (zip/7z/rar) into UNZIP_DIR/_nested for better YARA coverage.",
    )
    parser.add_argument(
        "--recursive-depth",
        type=int,
        default=1,
        help="Nested extraction depth (default: 1).",
    )
    parser.add_argument(
        "--move-archives",
        action="store_true",
        help="Move successfully extracted nested archives under UNZIP_DIR/_archives.",
    )
    parser.add_argument("--verbose", action="store_true", help="Show detailed process logs.")

    args = parser.parse_args()

    api_key = args.api_key or os.getenv("MB_API_KEY")
    if not api_key:
        parser.error("Missing API key. Provide --api_key or set MB_API_KEY in environment/.env.")

    # Validate input
    if not args.hash and not args.file:
        parser.error("Either --hash or --file must be specified.")

    # Ensure directories exist
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)
    os.makedirs(UNZIP_DIR, exist_ok=True)
    sess = requests.Session()

    if args.hash:
        # Process single hash
        if args.dry_run:
            print(args.hash)
            return
        zip_path = download_sample(sess, api_key, args.hash, verbose=args.verbose)
        if zip_path:
            extract_with_7z(zip_path, verbose=args.verbose)
            if args.recursive_extract and not args.dry_run:
                recursive_extract_nested(
                    UNZIP_DIR,
                    depth=max(1, int(args.recursive_depth)),
                    move_archives=bool(args.move_archives),
                    verbose=args.verbose,
                )

    if args.file:
        # Process multiple hashes from file
        if not os.path.exists(args.file):
            print(f"[ERROR] File '{args.file}' does not exist.")
            return

        with open(args.file, "r") as f:
            hash_list = [line.strip() for line in f if line.strip()]
            if args.limit and args.limit > 0:
                hash_list = hash_list[: args.limit]

            if args.dry_run:
                for sha256_hash in hash_list:
                    print(sha256_hash)
                return
            for sha256_hash in hash_list:
                zip_path = download_sample(sess, api_key, sha256_hash, verbose=args.verbose)
                if zip_path:
                    extract_with_7z(zip_path, verbose=args.verbose)
            if args.recursive_extract and not args.dry_run:
                recursive_extract_nested(
                    UNZIP_DIR,
                    depth=max(1, int(args.recursive_depth)),
                    move_archives=bool(args.move_archives),
                    verbose=args.verbose,
                )

if __name__ == "__main__":
    main()
